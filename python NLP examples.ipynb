{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Examples for Basic Natural Language Processing (NLP) \n",
    "\n",
    "## Introduction to NLP:\n",
    "Goal of NLP: convert text data into useful (structured) formats so that we can extract useful features based on NLP pipeline\n",
    "\n",
    "## NLP Terminology\n",
    "* A *document* can be a sentence, a paragraph or an article, represented by a sequence of N words/terms, denoted as $D = (t_1, t_2, ..., t_N)$.\n",
    "* A *corpus* is a collection of M text documents, denoted as $C = \\{D_1,D_2,...,D_M\\}$\n",
    "* A *dictionary* is a bag of all words that has presented in each of the document\n",
    "* *Document-Term (DT) matrix* is a summary matrix with each row corresponding to each document and columns corresponding to the terms in the dictionary.\n",
    "* *Term-Frequency (tf)* measures the raw frequency of each term occurs in a document, denoted as $tf(t, d_j)$, representing the number of times the term t appear in document $d_j$\n",
    "* *Stop words* are those useless words such as \"the\", \"a\", \"an\", \"in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "Document 1: the hello hello world\n",
    "\n",
    "Document 2: the hello\n",
    "\n",
    "Document 3: hi the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the dictionary becomes [the hello world hi]\n",
    "\n",
    "\n",
    "DT matrix =\\begin{vmatrix}\n",
    "1 & 2 & 1 & 0 \\\\\n",
    "1 & 1 & 0 & 0\\\\\n",
    "1 & 0 & 0 & 1\n",
    "\\end{vmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing \n",
    "\n",
    "The first step: turning the raw text documents into lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "raw_text = \"the hello hello world. the hello. hi the\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'hello', 'hello', 'world', '.', 'the', 'hello', '.', 'hi', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Split the raw text into individual words\n",
    "document = word_tokenize(raw_text)\n",
    "print document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to treat each sentence as a separate document - Sentence Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the hello hello world.', 'the hello.', 'hi the']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Split raw text in individual sentences\n",
    "docs = sent_tokenize(raw_text)\n",
    "print docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'hello', 'hello', 'world', '.'], ['the', 'hello', '.'], ['hi', 'the']]\n"
     ]
    }
   ],
   "source": [
    "# Split individual sentences into words\n",
    "corpus = []\n",
    "for doc in docs:\n",
    "    corpus.append(word_tokenize(doc))\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term (DT) matrix\n",
    "Document-Term (DT) matrix is a summary matrix with each row corresponding to each document and columns corresponding to the terms in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the hello hello world.', 'the hello.', 'hi the']\n",
      "{u'world': 3, u'the': 2, u'hi': 1, u'hello': 0}\n",
      "[u'hello', u'hi', u'the', u'world']\n",
      "[[2 0 1 1]\n",
      " [1 0 1 0]\n",
      " [0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = sent_tokenize(raw_text)\n",
    "print corpus\n",
    "\n",
    "# Build a bag of words model\n",
    "v = CountVectorizer()\n",
    "print v.fit(corpus).vocabulary_\n",
    "print(v.get_feature_names())\n",
    "print v.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency (idf) \n",
    "IDF is a measure of the importance of each term in a document with respect to the whole corpus. Rather than treating each term equally important, IDF assigns each of them a weight to scale up the rare terms and scale down the frequent ones. In such a way, stop words like ”the”, ”that”, ”if” and ”is” will get less weights than other more important words. IDF weights are defined as: $idf_{t,D}=log[\\frac{|M|}{|d \\in D: t \\in D|}]+1$, where $|M|$ is the total number of documents in the corpus and $|d \\in D: t \\in D|$ is number of documents where the term t occurs. Note that for each corpus, idf is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "tf-idf is a popular weighting scheme to normalize the raw frequency. It can be computed as: $tfidf(t,d) = tf(t,d) \\times idf(t,d)$, By multiplying idf to tf, tf-idf returns the relative frequency of each term in the entire collection of documents. It is also known as a stop-words-filtering technique.\n",
    "\n",
    "\n",
    "### Computing  TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.81093022  0.          1.          2.09861229]\n",
      " [ 1.40546511  0.          1.          0.        ]\n",
      " [ 0.          2.09861229  1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "bag_of_words_matrix = v.fit_transform(corpus).toarray()\n",
    "document_freq = np.sum(bag_of_words_matrix > 0, axis=0)\n",
    "#print document_freq\n",
    "\n",
    "# M is the number of documents\n",
    "M = bag_of_words_matrix.shape[0]\n",
    "\n",
    "idf = np.log(float(M) / (document_freq)) + 1 \n",
    "tfidf = np.multiply(bag_of_words_matrix, idf)\n",
    "#tfidf = normalize(tfidf, axis=12)\n",
    "print tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.81093022  0.          1.          2.09861229]\n",
      " [ 1.40546511  0.          1.          0.        ]\n",
      " [ 0.          2.09861229  1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# or we can use python library to compute tfidf\n",
    "# Documentation:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=None, smooth_idf=False)\n",
    "print tfidf.fit_transform(bag_of_words_matrix).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "N-grams or Ngrams are strings consecutive words in your corpus (can be used to train a machine learning model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'hello')\n",
      "('hello', 'hello')\n",
      "('hello', 'world')\n",
      "('world', '.')\n",
      "('.', 'the')\n",
      "('the', 'hello')\n",
      "('hello', '.')\n",
      "('.', 'hi')\n",
      "('hi', 'the')\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# An example of 2-grams in our document above.\n",
    "for token in ngrams(document , 2):\n",
    "    print token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Word\n",
    "Stop words are those useless words such as \"the\", \"a\", \"an\", \"in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "## To check the list of stopwords in python\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'hello', 'world', '.', 'hello', '.', 'hi']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from our documents\n",
    "\n",
    "document = [a for a in map(lambda x: x.lower(), document) if not a in stopwords.words('english')]\n",
    "print document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are also called text normalization\n",
    "\n",
    "For example: \n",
    "* play, playing, played --> play\n",
    "* better --> good\n",
    "* mice --> mouse\n",
    "* keys --> key\n",
    "\n",
    "NLTK in python provides several famous stemmers interfaces, such as Porter stemmer, Lancaster Stemmer, Snowball Stemmer and etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "play\n",
      "play\n",
      "play\n",
      "mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "example_doc = ['play','played','playing']\n",
    "ps = PorterStemmer()\n",
    "for t in example_doc:\n",
    "    print(ps.stem(t))\n",
    "    \n",
    "print SnowballStemmer('english').stem('plays')\n",
    "\n",
    "print WordNetLemmatizer().lemmatize('mice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An interesting example: Sentiment Analysis with Python NLTK Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "stop_words_set = set(stopwords.words('english'))\n",
    " \n",
    "def extractFeature(paragraph):\n",
    "    feature_dict = dict()\n",
    "    words = word_tokenize(paragraph)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "    if word not in stop_words_set and word.isalpha():\n",
    "        feature_dict[word] = True\n",
    "    return feature_dict\n",
    " \n",
    "training_data = []\n",
    "for fileid in movie_reviews.fileids():\n",
    "    feature_pos = extractFeature(movie_reviews.raw(fileid))\n",
    "    training_data.append((feature_pos, fileid[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "stop_words_set = set(stopwords.words('english'))\n",
    " \n",
    "def getFeatures(text):\n",
    "    feature_dict = dict()\n",
    "    words = word_tokenize(text)\n",
    "    for token in words:\n",
    "        token = token.lower()\n",
    "        if token not in stop_words_set and token.isalpha():\n",
    "            feature_dict[token] = True\n",
    "    return feature_dict\n",
    " \n",
    "train_data = []\n",
    "for fileid in movie_reviews.fileids():\n",
    "    features = getFeatures(movie_reviews.raw(fileid))\n",
    "    train_data.append((features, fileid[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'accident': True,\n",
       "  u'actors': True,\n",
       "  u'actually': True,\n",
       "  u'ago': True,\n",
       "  u'also': True,\n",
       "  u'although': True,\n",
       "  u'always': True,\n",
       "  u'american': True,\n",
       "  u'apparently': True,\n",
       "  u'apparitions': True,\n",
       "  u'applaud': True,\n",
       "  u'arrow': True,\n",
       "  u'assuming': True,\n",
       "  u'attempt': True,\n",
       "  u'audience': True,\n",
       "  u'away': True,\n",
       "  u'back': True,\n",
       "  u'bad': True,\n",
       "  u'beauty': True,\n",
       "  u'bentley': True,\n",
       "  u'big': True,\n",
       "  u'biggest': True,\n",
       "  u'bit': True,\n",
       "  u'blair': True,\n",
       "  u'bottom': True,\n",
       "  u'break': True,\n",
       "  u'came': True,\n",
       "  u'character': True,\n",
       "  u'characters': True,\n",
       "  u'chase': True,\n",
       "  u'chasing': True,\n",
       "  u'chopped': True,\n",
       "  u'church': True,\n",
       "  u'clue': True,\n",
       "  u'coming': True,\n",
       "  u'completely': True,\n",
       "  u'concept': True,\n",
       "  u'confusing': True,\n",
       "  u'continues': True,\n",
       "  u'cool': True,\n",
       "  u'correctly': True,\n",
       "  u'couples': True,\n",
       "  u'craziness': True,\n",
       "  u'critique': True,\n",
       "  u'crow': True,\n",
       "  u'dead': True,\n",
       "  u'deal': True,\n",
       "  u'decent': True,\n",
       "  u'decided': True,\n",
       "  u'despite': True,\n",
       "  u'dies': True,\n",
       "  u'different': True,\n",
       "  u'dig': True,\n",
       "  u'director': True,\n",
       "  u'disappearances': True,\n",
       "  u'downshifts': True,\n",
       "  u'dreams': True,\n",
       "  u'drink': True,\n",
       "  u'drive': True,\n",
       "  u'echoes': True,\n",
       "  u'edge': True,\n",
       "  u'elm': True,\n",
       "  u'ending': True,\n",
       "  u'engaging': True,\n",
       "  u'enter': True,\n",
       "  u'entertain': True,\n",
       "  u'entertaining': True,\n",
       "  u'entire': True,\n",
       "  u'even': True,\n",
       "  u'ever': True,\n",
       "  u'every': True,\n",
       "  u'exact': True,\n",
       "  u'excites': True,\n",
       "  u'executed': True,\n",
       "  u'explained': True,\n",
       "  u'explanation': True,\n",
       "  u'fantasy': True,\n",
       "  u'fed': True,\n",
       "  u'feeling': True,\n",
       "  u'feels': True,\n",
       "  u'figured': True,\n",
       "  u'film': True,\n",
       "  u'films': True,\n",
       "  u'final': True,\n",
       "  u'find': True,\n",
       "  u'five': True,\n",
       "  u'flick': True,\n",
       "  u'flicks': True,\n",
       "  u'folks': True,\n",
       "  u'generally': True,\n",
       "  u'generation': True,\n",
       "  u'genre': True,\n",
       "  u'get': True,\n",
       "  u'girlfriend': True,\n",
       "  u'give': True,\n",
       "  u'given': True,\n",
       "  u'giving': True,\n",
       "  u'go': True,\n",
       "  u'going': True,\n",
       "  u'good': True,\n",
       "  u'got': True,\n",
       "  u'guess': True,\n",
       "  u'guys': True,\n",
       "  u'happen': True,\n",
       "  u'harder': True,\n",
       "  u'head': True,\n",
       "  u'hide': True,\n",
       "  u'highway': True,\n",
       "  u'holds': True,\n",
       "  u'horror': True,\n",
       "  u'hot': True,\n",
       "  u'idea': True,\n",
       "  u'insight': True,\n",
       "  u'joblo': True,\n",
       "  u'jumbled': True,\n",
       "  u'kids': True,\n",
       "  u'kind': True,\n",
       "  u'know': True,\n",
       "  u'kudos': True,\n",
       "  u'lazy': True,\n",
       "  u'life': True,\n",
       "  u'like': True,\n",
       "  u'line': True,\n",
       "  u'little': True,\n",
       "  u'look': True,\n",
       "  u'looooot': True,\n",
       "  u'lost': True,\n",
       "  u'main': True,\n",
       "  u'make': True,\n",
       "  u'makes': True,\n",
       "  u'making': True,\n",
       "  u'mean': True,\n",
       "  u'meantime': True,\n",
       "  u'melissa': True,\n",
       "  u'member': True,\n",
       "  u'memento': True,\n",
       "  u'mess': True,\n",
       "  u'might': True,\n",
       "  u'mind': True,\n",
       "  u'minutes': True,\n",
       "  u'mold': True,\n",
       "  u'movie': True,\n",
       "  u'movies': True,\n",
       "  u'music': True,\n",
       "  u'neat': True,\n",
       "  u'need': True,\n",
       "  u'neighborhood': True,\n",
       "  u'new': True,\n",
       "  u'nightmare': True,\n",
       "  u'nightmares': True,\n",
       "  u'normal': True,\n",
       "  u'obviously': True,\n",
       "  u'offering': True,\n",
       "  u'oh': True,\n",
       "  u'okay': True,\n",
       "  u'one': True,\n",
       "  u'others': True,\n",
       "  u'overall': True,\n",
       "  u'package': True,\n",
       "  u'packaged': True,\n",
       "  u'part': True,\n",
       "  u'party': True,\n",
       "  u'password': True,\n",
       "  u'people': True,\n",
       "  u'personally': True,\n",
       "  u'plain': True,\n",
       "  u'playing': True,\n",
       "  u'plot': True,\n",
       "  u'point': True,\n",
       "  u'presents': True,\n",
       "  u'pretty': True,\n",
       "  u'problem': True,\n",
       "  u'problems': True,\n",
       "  u'production': True,\n",
       "  u'rarely': True,\n",
       "  u'really': True,\n",
       "  u'redundant': True,\n",
       "  u'review': True,\n",
       "  u'running': True,\n",
       "  u'runtime': True,\n",
       "  u'sad': True,\n",
       "  u'sagemiller': True,\n",
       "  u'salvation': True,\n",
       "  u'scenes': True,\n",
       "  u'secret': True,\n",
       "  u'see': True,\n",
       "  u'seem': True,\n",
       "  u'seemed': True,\n",
       "  u'seems': True,\n",
       "  u'sense': True,\n",
       "  u'shelves': True,\n",
       "  u'showing': True,\n",
       "  u'shows': True,\n",
       "  u'simply': True,\n",
       "  u'since': True,\n",
       "  u'sitting': True,\n",
       "  u'skip': True,\n",
       "  u'slasher': True,\n",
       "  u'snag': True,\n",
       "  u'someone': True,\n",
       "  u'somewhere': True,\n",
       "  u'sorta': True,\n",
       "  u'start': True,\n",
       "  u'starts': True,\n",
       "  u'stick': True,\n",
       "  u'still': True,\n",
       "  u'stir': True,\n",
       "  u'strange': True,\n",
       "  u'strangeness': True,\n",
       "  u'street': True,\n",
       "  u'studio': True,\n",
       "  u'suits': True,\n",
       "  u'sure': True,\n",
       "  u'taken': True,\n",
       "  u'teen': True,\n",
       "  u'terribly': True,\n",
       "  u'things': True,\n",
       "  u'thrilling': True,\n",
       "  u'throughout': True,\n",
       "  u'tons': True,\n",
       "  u'took': True,\n",
       "  u'touches': True,\n",
       "  u'trying': True,\n",
       "  u'turning': True,\n",
       "  u'two': True,\n",
       "  u'types': True,\n",
       "  u'understanding': True,\n",
       "  u'unravel': True,\n",
       "  u'unraveling': True,\n",
       "  u'us': True,\n",
       "  u'video': True,\n",
       "  u'visions': True,\n",
       "  u'want': True,\n",
       "  u'watch': True,\n",
       "  u'way': True,\n",
       "  u'ways': True,\n",
       "  u'weird': True,\n",
       "  u'well': True,\n",
       "  u'wes': True,\n",
       "  u'whatever': True,\n",
       "  u'witch': True,\n",
       "  u'world': True,\n",
       "  u'would': True,\n",
       "  u'wrapped': True,\n",
       "  u'write': True,\n",
       "  u'years': True},\n",
       " u'neg')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'accident': True,\n",
       "  u'actions': True,\n",
       "  u'address': True,\n",
       "  u'airplane': True,\n",
       "  u'almost': True,\n",
       "  u'also': True,\n",
       "  u'although': True,\n",
       "  u'amazing': True,\n",
       "  u'americans': True,\n",
       "  u'andrew': True,\n",
       "  u'announcer': True,\n",
       "  u'another': True,\n",
       "  u'answer': True,\n",
       "  u'apart': True,\n",
       "  u'apparently': True,\n",
       "  u'appears': True,\n",
       "  u'around': True,\n",
       "  u'aroused': True,\n",
       "  u'artificial': True,\n",
       "  u'asked': True,\n",
       "  u'attack': True,\n",
       "  u'awakening': True,\n",
       "  u'back': True,\n",
       "  u'beautiful': True,\n",
       "  u'became': True,\n",
       "  u'becomes': True,\n",
       "  u'behind': True,\n",
       "  u'best': True,\n",
       "  u'better': True,\n",
       "  u'big': True,\n",
       "  u'breaks': True,\n",
       "  u'brings': True,\n",
       "  u'brisk': True,\n",
       "  u'building': True,\n",
       "  u'built': True,\n",
       "  u'burbank': True,\n",
       "  u'california': True,\n",
       "  u'came': True,\n",
       "  u'cameo': True,\n",
       "  u'camera': True,\n",
       "  u'cameras': True,\n",
       "  u'capitalized': True,\n",
       "  u'captive': True,\n",
       "  u'car': True,\n",
       "  u'cards': True,\n",
       "  u'carefully': True,\n",
       "  u'carrey': True,\n",
       "  u'carrying': True,\n",
       "  u'center': True,\n",
       "  u'certainly': True,\n",
       "  u'change': True,\n",
       "  u'chaos': True,\n",
       "  u'character': True,\n",
       "  u'choice': True,\n",
       "  u'christof': True,\n",
       "  u'classic': True,\n",
       "  u'clicked': True,\n",
       "  u'coffee': True,\n",
       "  u'coincidence': True,\n",
       "  u'combine': True,\n",
       "  u'comes': True,\n",
       "  u'coming': True,\n",
       "  u'communities': True,\n",
       "  u'compare': True,\n",
       "  u'competently': True,\n",
       "  u'concept': True,\n",
       "  u'concepts': True,\n",
       "  u'corners': True,\n",
       "  u'counting': True,\n",
       "  u'covering': True,\n",
       "  u'creator': True,\n",
       "  u'criticize': True,\n",
       "  u'day': True,\n",
       "  u'deal': True,\n",
       "  u'death': True,\n",
       "  u'describes': True,\n",
       "  u'determined': True,\n",
       "  u'dinosaurs': True,\n",
       "  u'disappointed': True,\n",
       "  u'distracted': True,\n",
       "  u'door': True,\n",
       "  u'doors': True,\n",
       "  u'drama': True,\n",
       "  u'dream': True,\n",
       "  u'drive': True,\n",
       "  u'driven': True,\n",
       "  u'earlier': True,\n",
       "  u'easily': True,\n",
       "  u'edge': True,\n",
       "  u'elaborate': True,\n",
       "  u'elevator': True,\n",
       "  u'else': True,\n",
       "  u'end': True,\n",
       "  u'ends': True,\n",
       "  u'enters': True,\n",
       "  u'entire': True,\n",
       "  u'epic': True,\n",
       "  u'era': True,\n",
       "  u'escape': True,\n",
       "  u'ethics': True,\n",
       "  u'even': True,\n",
       "  u'every': True,\n",
       "  u'everything': True,\n",
       "  u'exactly': True,\n",
       "  u'exclusive': True,\n",
       "  u'expense': True,\n",
       "  u'explaining': True,\n",
       "  u'explains': True,\n",
       "  u'fair': True,\n",
       "  u'fake': True,\n",
       "  u'falling': True,\n",
       "  u'falls': True,\n",
       "  u'family': True,\n",
       "  u'father': True,\n",
       "  u'fear': True,\n",
       "  u'felt': True,\n",
       "  u'film': True,\n",
       "  u'films': True,\n",
       "  u'find': True,\n",
       "  u'first': True,\n",
       "  u'following': True,\n",
       "  u'forward': True,\n",
       "  u'found': True,\n",
       "  u'frantic': True,\n",
       "  u'functioning': True,\n",
       "  u'gattaca': True,\n",
       "  u'get': True,\n",
       "  u'gets': True,\n",
       "  u'glass': True,\n",
       "  u'got': True,\n",
       "  u'government': True,\n",
       "  u'grab': True,\n",
       "  u'great': True,\n",
       "  u'green': True,\n",
       "  u'grim': True,\n",
       "  u'grip': True,\n",
       "  u'guards': True,\n",
       "  u'handled': True,\n",
       "  u'happens': True,\n",
       "  u'happy': True,\n",
       "  u'help': True,\n",
       "  u'hidden': True,\n",
       "  u'hits': True,\n",
       "  u'hoax': True,\n",
       "  u'hollywood': True,\n",
       "  u'home': True,\n",
       "  u'hope': True,\n",
       "  u'idea': True,\n",
       "  u'ideas': True,\n",
       "  u'idyllic': True,\n",
       "  u'impact': True,\n",
       "  u'instant': True,\n",
       "  u'interesting': True,\n",
       "  u'interviews': True,\n",
       "  u'introduces': True,\n",
       "  u'jams': True,\n",
       "  u'jim': True,\n",
       "  u'jurassic': True,\n",
       "  u'keep': True,\n",
       "  u'keeping': True,\n",
       "  u'keyboardist': True,\n",
       "  u'know': True,\n",
       "  u'known': True,\n",
       "  u'last': True,\n",
       "  u'leads': True,\n",
       "  u'learning': True,\n",
       "  u'led': True,\n",
       "  u'life': True,\n",
       "  u'light': True,\n",
       "  u'like': True,\n",
       "  u'listeners': True,\n",
       "  u'little': True,\n",
       "  u'lives': True,\n",
       "  u'long': True,\n",
       "  u'look': True,\n",
       "  u'looking': True,\n",
       "  u'lounge': True,\n",
       "  u'lower': True,\n",
       "  u'made': True,\n",
       "  u'man': True,\n",
       "  u'may': True,\n",
       "  u'meanwhile': True,\n",
       "  u'memory': True,\n",
       "  u'mind': True,\n",
       "  u'missed': True,\n",
       "  u'movements': True,\n",
       "  u'moves': True,\n",
       "  u'movie': True,\n",
       "  u'much': True,\n",
       "  u'music': True,\n",
       "  u'name': True,\n",
       "  u'names': True,\n",
       "  u'nbc': True,\n",
       "  u'nearly': True,\n",
       "  u'necessary': True,\n",
       "  u'neither': True,\n",
       "  u'nevertheless': True,\n",
       "  u'next': True,\n",
       "  u'niccol': True,\n",
       "  u'normal': True,\n",
       "  u'numbers': True,\n",
       "  u'nurse': True,\n",
       "  u'obscuring': True,\n",
       "  u'obstructions': True,\n",
       "  u'ocean': True,\n",
       "  u'oddities': True,\n",
       "  u'office': True,\n",
       "  u'one': True,\n",
       "  u'open': True,\n",
       "  u'opens': True,\n",
       "  u'opportunities': True,\n",
       "  u'opus': True,\n",
       "  u'overall': True,\n",
       "  u'overflying': True,\n",
       "  u'pacing': True,\n",
       "  u'pain': True,\n",
       "  u'paneled': True,\n",
       "  u'park': True,\n",
       "  u'part': True,\n",
       "  u'particularly': True,\n",
       "  u'pedestrian': True,\n",
       "  u'people': True,\n",
       "  u'perfect': True,\n",
       "  u'performance': True,\n",
       "  u'perhaps': True,\n",
       "  u'permeates': True,\n",
       "  u'person': True,\n",
       "  u'philip': True,\n",
       "  u'pick': True,\n",
       "  u'picking': True,\n",
       "  u'picture': True,\n",
       "  u'place': True,\n",
       "  u'planned': True,\n",
       "  u'plenty': True,\n",
       "  u'plot': True,\n",
       "  u'point': True,\n",
       "  u'powaqqatsi': True,\n",
       "  u'president': True,\n",
       "  u'program': True,\n",
       "  u'promised': True,\n",
       "  u'properly': True,\n",
       "  u'protagonist': True,\n",
       "  u'psychological': True,\n",
       "  u'quality': True,\n",
       "  u'quell': True,\n",
       "  u'questions': True,\n",
       "  u'quick': True,\n",
       "  u'quickly': True,\n",
       "  u'radio': True,\n",
       "  u'real': True,\n",
       "  u'reality': True,\n",
       "  u'really': True,\n",
       "  u'recalls': True,\n",
       "  u'right': True,\n",
       "  u'robots': True,\n",
       "  u'root': True,\n",
       "  u'sail': True,\n",
       "  u'sake': True,\n",
       "  u'saw': True,\n",
       "  u'says': True,\n",
       "  u'scene': True,\n",
       "  u'scenes': True,\n",
       "  u'scientists': True,\n",
       "  u'score': True,\n",
       "  u'scored': True,\n",
       "  u'screen': True,\n",
       "  u'scripted': True,\n",
       "  u'security': True,\n",
       "  u'see': True,\n",
       "  u'seemed': True,\n",
       "  u'seems': True,\n",
       "  u'sees': True,\n",
       "  u'set': True,\n",
       "  u'setup': True,\n",
       "  u'shot': True,\n",
       "  u'show': True,\n",
       "  u'showed': True,\n",
       "  u'sight': True,\n",
       "  u'sign': True,\n",
       "  u'sky': True,\n",
       "  u'slows': True,\n",
       "  u'small': True,\n",
       "  u'smidgen': True,\n",
       "  u'snoots': True,\n",
       "  u'something': True,\n",
       "  u'sooner': True,\n",
       "  u'sort': True,\n",
       "  u'sound': True,\n",
       "  u'sounds': True,\n",
       "  u'spite': True,\n",
       "  u'square': True,\n",
       "  u'started': True,\n",
       "  u'starts': True,\n",
       "  u'stature': True,\n",
       "  u'still': True,\n",
       "  u'stopped': True,\n",
       "  u'stories': True,\n",
       "  u'story': True,\n",
       "  u'straight': True,\n",
       "  u'studio': True,\n",
       "  u'subject': True,\n",
       "  u'subjecting': True,\n",
       "  u'suspicion': True,\n",
       "  u'suspicious': True,\n",
       "  u'take': True,\n",
       "  u'tangerine': True,\n",
       "  u'television': True,\n",
       "  u'terms': True,\n",
       "  u'theme': True,\n",
       "  u'theory': True,\n",
       "  u'think': True,\n",
       "  u'throw': True,\n",
       "  u'timbre': True,\n",
       "  u'title': True,\n",
       "  u'token': True,\n",
       "  u'told': True,\n",
       "  u'tonight': True,\n",
       "  u'town': True,\n",
       "  u'trap': True,\n",
       "  u'trauma': True,\n",
       "  u'tries': True,\n",
       "  u'trouble': True,\n",
       "  u'truman': True,\n",
       "  u'truth': True,\n",
       "  u'try': True,\n",
       "  u'trying': True,\n",
       "  u'turn': True,\n",
       "  u'tv': True,\n",
       "  u'two': True,\n",
       "  u'type': True,\n",
       "  u'unassuming': True,\n",
       "  u'unaware': True,\n",
       "  u'unnecessarily': True,\n",
       "  u'vainly': True,\n",
       "  u'view': True,\n",
       "  u'voice': True,\n",
       "  u'wanders': True,\n",
       "  u'war': True,\n",
       "  u'warns': True,\n",
       "  u'way': True,\n",
       "  u'weir': True,\n",
       "  u'well': True,\n",
       "  u'westworld': True,\n",
       "  u'whatever': True,\n",
       "  u'whether': True,\n",
       "  u'wife': True,\n",
       "  u'wondering': True,\n",
       "  u'work': True,\n",
       "  u'world': True,\n",
       "  u'worlds': True,\n",
       "  u'worldwide': True,\n",
       "  u'worse': True,\n",
       "  u'would': True,\n",
       "  u'written': True},\n",
       " u'pos')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n"
     ]
    }
   ],
   "source": [
    "fit = NaiveBayesClassifier.train(train_data)\n",
    "accuracy = nltk.classify.util.accuracy(fit, train_data)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'neg'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set1 = 'Such a bad movie! Terrible!'\n",
    "feature_test1 = getFeatures(test_set1)\n",
    "fit.classify(feature_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'pos'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2 = 'I love it!'\n",
    "feature_test2 = getFeatures(test_set2)\n",
    "fit.classify(feature_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We can see that based on the model prediction, the review 'Such a bad movie! Terrible!' was classified as a negative review while 'I love it!' was classified as a positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
